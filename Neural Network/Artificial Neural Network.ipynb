{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seasonal-volume",
   "metadata": {},
   "source": [
    "# Artifical Neural Network  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-tactics",
   "metadata": {},
   "source": [
    "## Lab Objective  \n",
    "  \n",
    "To understand the fundamentals of artificial neural network and its capabilities.  \n",
    "  \n",
    "The contents in this lab course:\n",
    "1. Limitations of linear model\n",
    "2. Introduction to artificial neural network\n",
    "3. Introduction to PyTorch\n",
    "4. Non-linear model\n",
    "  \n",
    "## Introduction  \n",
    "In our previous lab, we covered the mechanics of gradient descent and how to apply it to learn the coefficients for linear regression.  \n",
    "In this lab, we will be explaining the limitations of linear models and utilizing gradient descent to optimize and learn a type of non-linear models called artificial neural network.   \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-monthly",
   "metadata": {},
   "source": [
    "## Limitations of linear model\n",
    "Linear models are great for modelling the relationship between independent variables and dependent variables.  \n",
    "However, the usage of linear models requires a very strong assumption of a linear relationship between the independent variables and the dependent variable.  \n",
    "In cases where our assumption of linear relationship is false, naive application of linear model will not enable us to effectively predict the expected value of a dependent variable.  \n",
    "  \n",
    "Consider an example scenario where u have to pack <b>cube-shaped carton boxes</b> into a large <b>cube-shaped crate.</b>  \n",
    "For each shipment, there is variable $x_1$, $x_2$ that linearly determines the size for the sides $S(x_1, x_2)$ of the carton boxes.\n",
    "$$S(x_1, x_2) = a_1x_1 + a_2x_2 + b$$  \n",
    "With prior knowledge, we know that the volume of a cube is $x^3$ if the side of the cube is $x$.  \n",
    "Therefore, the number of crate needed to fit $n$ number of carton boxes is $\\frac{nx_{carton}^3}{x_{crate}^3}$.\n",
    "  \n",
    "  \n",
    "For the exercise below, let us assume we do not have prior knowledge and we are tasked to predict the <b>number of crates needed to store 100 carton boxes</b> given $x_1$, $x_2$ and a fixed size crate of <b>1 unit</b> on each side.\n",
    "Train a linear model $F(x_1, x_2)$ such that $F(x1, x2) \\approx \\frac{100S(x_1, x_2)^3}{1^3} = 100S(x_1, x_2)^3$\n",
    "\n",
    "<img src=\"img/carton-example.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-growth",
   "metadata": {},
   "source": [
    "Let us start by importing all the required packages for this lab. üòÅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chicken-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-disposition",
   "metadata": {},
   "source": [
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "innocent-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('crate_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-picture",
   "metadata": {},
   "source": [
    "Checking the shape and dtype of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empirical-multimedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1999 entries, 0 to 1998\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   X_1           1999 non-null   float64\n",
      " 1   X_2           1999 non-null   float64\n",
      " 2   Crate_Size    1999 non-null   float64\n",
      " 3   Carton_Count  1999 non-null   int64  \n",
      " 4   Crate_Count   1999 non-null   int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-riding",
   "metadata": {},
   "source": [
    "Extract data rows where Crate_Size is 1 and Carton_Count is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "placed-labor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>Crate_Size</th>\n",
       "      <th>Carton_Count</th>\n",
       "      <th>Crate_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734962</td>\n",
       "      <td>0.764115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.276701</td>\n",
       "      <td>0.522430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.226746</td>\n",
       "      <td>0.643608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.997268</td>\n",
       "      <td>0.720236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.877842</td>\n",
       "      <td>0.770019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>0.455579</td>\n",
       "      <td>0.595635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>0.679031</td>\n",
       "      <td>0.136803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>0.719751</td>\n",
       "      <td>0.343072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>0.832171</td>\n",
       "      <td>0.051791</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.266509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X_1       X_2  Crate_Size  Carton_Count  Crate_Count\n",
       "2     0.734962  0.764115         1.0           100           41\n",
       "22    0.276701  0.522430         1.0           100            4\n",
       "23    0.226746  0.643608         1.0           100            3\n",
       "37    0.997268  0.720236         1.0           100           84\n",
       "41    0.877842  0.770019         1.0           100           63\n",
       "...        ...       ...         ...           ...          ...\n",
       "1941  0.455579  0.595635         1.0           100           12\n",
       "1948  0.679031  0.136803         1.0           100           19\n",
       "1963  0.719751  0.343072         1.0           100           27\n",
       "1965  0.832171  0.051791         1.0           100           31\n",
       "1980  0.478056  0.266509         1.0           100            9\n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[(dataset.Crate_Size==1) & (dataset.Carton_Count==100)]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-consideration",
   "metadata": {},
   "source": [
    "Do a linear regression to predict **Crate_Count** using **X_1** and **X_2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "informative-wrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in the code to do a linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(dataset[['X_1', 'X_2']], dataset['Crate_Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-concern",
   "metadata": {},
   "source": [
    "Check the $R^2$ of the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "synthetic-sewing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68.2849929 , 17.64339752])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill in the code to calculate the R^2 of our trained model\n",
    "from sklearn.metrics import explained_variance_score\n",
    "linreg.score(dataset[['X_1', 'X_2']], dataset['Crate_Count'])\n",
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-karma",
   "metadata": {},
   "source": [
    "## Improving the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-retro",
   "metadata": {},
   "source": [
    "Since we know that the function for calculating the number of crate boxes is a 3rd degree polynomial function, we can add a 2 new features **X_1POW3** representing ${X_1}^3$ and **X_2POW3** representing ${X_2}^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "worse-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the code to create 2 new features/columns X_1POW3, X_2POW3\n",
    "dataset['X_1POW3'] = dataset.apply(lambda x:x.X_1 ** 3, axis=1)\n",
    "dataset['X_2POW3'] = dataset.apply(lambda x:x.X_2 ** 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "technical-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['X_3POW3'] = dataset.apply(lambda x:x.X_2 ** 2 * x.X_1, axis=1)\n",
    "dataset['X_4POW3'] = dataset.apply(lambda x:x.X_1 ** 2 * x.X_2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-today",
   "metadata": {},
   "source": [
    "Do a linear regression to predict **Crate_Count** using **X_1POW3** and **X_2POW3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "close-vision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = sklearn.linear_model.LinearRegression()\n",
    "linreg.fit(dataset[['X_1POW3', 'X_2POW3','X_3POW3', 'X_4POW3']], dataset['Crate_Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-bracket",
   "metadata": {},
   "source": [
    "Check the $R^2$ of the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "streaming-artwork",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998236571350905"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.score(dataset[['X_1POW3', 'X_2POW3','X_3POW3','X_4POW3']], dataset['Crate_Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-issue",
   "metadata": {},
   "source": [
    "## Introduction to artificial neural network\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-hobby",
   "metadata": {},
   "source": [
    "As visualized from our exercise above, we are able to leverage on our prior knowledge that the function is a 3rd degree polynomial function to engineer features **X_1POW3** and **X_2POW3** and train a better model.  \n",
    "  \n",
    "However, what happens if we are unable to identify the non-linearity of our data? What if we engineered $X\\_1POW3={X_1}^{-3}$ and $X\\_2POW3={X_2}^{-3}$ for our linear model?  \n",
    "  \n",
    "This leads to a general question of whether it is possible to learn the non-linearity just as we have learnt the relationship of between dependent variable and independent variables in linear regression.  \n",
    "  \n",
    "By using artificial neural network, we are able to train a non-linear model that approximates both the non-linearity and relationship between dependent variable and independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-ivory",
   "metadata": {},
   "source": [
    "### Artificial neural network\n",
    "Artificial neural network is a non-linear model that can be used to approximate any continuous function.\n",
    "It works by stacking layers of linear functions with a non-linearity between each layer. Each filled circle in the image below represents a linear function.  \n",
    "![Universal Function Approximator](img/ann-universal.png)\n",
    "By doing so, each successive layer in a neural network is able to compose a linear combination of <b>non-linear functions (neurons)</b> producing a richer expression that can better approximate the target function. In fact, it has been proven by many researchers that an artificial neural network with a single non-linear hidden layer is sufficient to approximate any continuous function of $n$ variables. Some of the more common non-linear functions used in modern neural networks are listed below:\n",
    "![Sigmoid](img/sigmoid.png)\n",
    "$$\\sigma_{sigmoid}(x)=\\frac{1}{1+e^{-x}}$$\n",
    "![Tanh](img/tanh.png)\n",
    "$$\\sigma_{tanh}(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}$$\n",
    "![Relu](img/relu.png)\n",
    "$$\n",
    "\\sigma_{relu}(x) = \\left\\{ \\begin{array}{rl}\n",
    "0 &\\mbox{ if $x<0$} \\\\\n",
    "x &\\mbox{ otherwise}\n",
    "\\end{array} \\right.\n",
    "$$  \n",
    "  \n",
    "  \n",
    "In mathematical formulation a simple 2-layer neural network can be expressed as the formula below, where $X$ is a row vector of data features, $A_1$ is a matrix of coefficients for the first layer, $B_1$ is a row vector of biases for the first layer, $A_2$ is a matrix of coefficients for the second layer, $B_2$ is a row vector of biases for the second layer, $\\sigma$ represents our non-linearity function and $F_{neural}$ represents our 2-layer neural network model.\n",
    "$$X=\\begin{bmatrix}x_1 & x_2 & ... & x_n\\end{bmatrix}$$  \n",
    "\n",
    "$$A_1=\\begin{bmatrix}a_{1_1^1} & a_{1_2^1} & ... & a_{1_k^1} \\\\ .&.&...&. \\\\ a_{1_1^n} & a_{1_2^n} & ... & a_{1_k^n}\\end{bmatrix}$$  \n",
    "\n",
    "$$B_1=\\begin{bmatrix}b_1 & b_2 & ... & b_k\\end{bmatrix}$$  \n",
    "  \n",
    "$$A_2=\\begin{bmatrix}a_{2_1^1} & a_{2_2^1} & ... & a_{2_r^1} \\\\ .&.&...&. \\\\ a_{2_1^k} & a_{2_2^k} & ... & a_{2_r^k}\\end{bmatrix}$$  \n",
    "\n",
    "$$B_2=\\begin{bmatrix}b_1 & b_2 & ... & b_r\\end{bmatrix}$$  \n",
    "\n",
    "$$\\sigma(\\begin{bmatrix}q_1 & q_2 & ... & q_k\\end{bmatrix})=\\begin{bmatrix}\\sigma(q_1) & \\sigma(q_2) & ... & \\sigma(q_k)\\end{bmatrix}$$\n",
    "\n",
    "$$F_{neural}(x)=\\sigma(XA_1+B_1)A_2 + B_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-sampling",
   "metadata": {},
   "source": [
    "#### Universal function approximator\n",
    "That is a lengthy mathematical formulation, but how can a linear combination of non-linear layer approximate any continuous function?  \n",
    "To answer this question, let us make use of $\\sigma_{relu}$ non-linearity for our explanations below.  \n",
    "  \n",
    "Let us first define our target function to be $y=sin(x)$.\n",
    "![sin(x)](img/sinx-break.png)\n",
    "One way we can visualize how a neural network with $\\sigma_{relu}$ as its non-linearity can approximate a target function is to break down the domain of the function we want to approximate into smaller pieces.  \n",
    "  \n",
    "Using the piecewise non-linearity characteristic of $\\sigma_{relu}$, we can first define the formula below to get an approximate function as depicted below in the blue line below. \n",
    "  \n",
    "$$F_{neural}(x)=\\frac{2\\left(\\sin\\left(\\frac{\\pi}{2}\\right)-\\sin\\left(0\\right)\\right)}{\\pi}\\sigma_{relu}(x)-\\frac{2\\left(\\sin\\left(\\frac{\\pi}{2}\\right)-\\sin\\left(0\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{\\pi}{2})+\\frac{\\left(\\sin\\left(\\frac{3\\pi}{2}\\right)-\\sin\\left(\\frac{\\pi}{2}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{\\pi}{2})-\\frac{\\left(\\sin\\left(\\frac{3\\pi}{2}\\right)-\\sin\\left(\\frac{\\pi}{2}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{3\\pi}{2})+\\frac{2\\left(\\sin\\left(2\\pi\\right)-\\sin\\left(\\frac{3\\pi}{2}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{3\\pi}{2})$$  \n",
    "Using a linear combination of 5 neurons from the hidden layer, we are able to obtain a rough approximation $sin(x)$ as depicted below.\n",
    "![sin(x)](img/sinx-approx-1.png)  \n",
    "By increasing the increasing the number of neurons from the hidden layer we can even achieve better approximation.  \n",
    "Let us see how $F_{neural}(x)$ with 15 neurons from the hidden layer provide better approximation for our target function.  \n",
    "  \n",
    "$$y=\\frac{4\\left(\\sin\\left(\\frac{\\pi}{4}\\right)-\\sin\\left(0\\right)\\right)}{\\pi}\\sigma_{relu}(x)-\\frac{4\\left(\\sin\\left(\\frac{\\pi}{4}\\right)-\\sin\\left(0\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{\\pi}{4})+\\frac{4\\left(\\sin\\left(\\frac{\\pi}{2}\\right)-\\sin\\left(\\frac{\\pi}{4}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{\\pi}{4})-\\frac{4\\left(\\sin\\left(\\frac{\\pi}{2}\\right)-\\sin\\left(\\frac{\\pi}{4}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{\\pi}{2})+\\frac{4\\left(\\sin\\left(\\frac{3\\pi}{4}\\right)-\\sin\\left(\\frac{\\pi}{2}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{\\pi}{2})-\\frac{4\\left(\\sin\\left(\\frac{3\\pi}{4}\\right)-\\sin\\left(\\frac{\\pi}{2}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{3\\pi}{4})+\\frac{4\\left(\\sin\\left(\\pi\\right)-\\sin\\left(\\frac{3\\pi}{4}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{3\\pi}{4})\\frac{3\\pi}{4}-\\frac{4\\left(\\sin\\left(\\pi\\right)-\\sin\\left(\\frac{3\\pi}{4}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\pi)+\\frac{4\\left(\\sin\\left(\\frac{5\\pi}{4}\\right)-\\sin\\left(\\pi\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\pi)-\\frac{4\\left(\\sin\\left(\\frac{5\\pi}{4}\\right)-\\sin\\left(\\pi\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{5\\pi}{4})+\\frac{4\\left(\\sin\\left(\\frac{3\\pi}{2}\\right)-\\sin\\left(\\frac{5\\pi}{4}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{5\\pi}{4})-\\frac{4\\left(\\sin\\left(\\frac{3\\pi}{2}\\right)-\\sin\\left(\\frac{5\\pi}{4}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{3\\pi}{2})+\\frac{4\\left(\\sin\\left(\\frac{7\\pi}{4}\\right)-\\sin\\left(\\frac{3\\pi}{2}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{3\\pi}{2})-\\frac{4\\left(\\sin\\left(\\frac{7\\pi}{4}\\right)-\\sin\\left(\\frac{3\\pi}{2}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{7\\pi}{4})+\\frac{4\\left(\\sin\\left(2\\pi\\right)-\\sin\\left(\\frac{7\\pi}{4}\\right)\\right)}{\\pi}\\sigma_{relu}(x-\\frac{7\\pi}{4})$$\n",
    "![sin(x)](img/sinx-approx-2.png)  \n",
    "  \n",
    "**Think**  \n",
    "Why would an artificial neural network need non-linear function between each layer? Would it still be able to approximate non-linear functions using a composition of linear function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-young",
   "metadata": {},
   "source": [
    "## Introduction to PyTorch  \n",
    "---  \n",
    "  \n",
    "Similar to the training of a linear model, the training of an artificial neural network can make use of gradient descent to search for the optimal parameter coefficient and biases for artificial neural network.\n",
    "However, the manual calculation of gradient approach we adopted for our linear model optimization is not going to be practical for artificial neural network as the number of parameters to be optimized is far more than that of a linear model and the calculation of the gradient of the loss function with respect to the parameters is also more complex as depth increases.  \n",
    "  \n",
    "<b>PyTorch</b> is an open-sourced framework developed to reduce the burden of deep learning researchers by eliminating the need of manual calculation of gradients. In addition to the above mentioned advantage, PyTorch also supports using hardware accelerators to accelerate the calculation of large matrix multiplication and automates parallel processing of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-tournament",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-charlotte",
   "metadata": {},
   "source": [
    "Let us define our first PyTorch model with 1 hidden layer with 64 neurons and ReLU non-linear activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "obvious-territory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=2, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=1)\n",
    ")\n",
    "my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-highlight",
   "metadata": {},
   "source": [
    "### Creating SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-victoria",
   "metadata": {},
   "source": [
    "Let us define a gradient descent optimizer to update our parameters iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "german-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(my_model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-testament",
   "metadata": {},
   "source": [
    "### Defining our loss function  \n",
    "Our loss function in this case would be the mean square error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "mathematical-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-calibration",
   "metadata": {},
   "source": [
    "### Update our model parameters  \n",
    "Execute the code cell below to perform a single step of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "further-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad() # Zero out gradients for all the parameters in our model\n",
    "\n",
    "predictors = torch.tensor(dataset[['X_1', 'X_2']].to_numpy(), dtype=torch.float32) # Convert Matrix to Pytorch datatype\n",
    "ground_truth = torch.tensor(dataset[['Crate_Count']].to_numpy(), dtype=torch.float32) # Converting Response variable also\n",
    "\n",
    "prediction = my_model(predictors)\n",
    "loss_value = loss_function(prediction, ground_truth)\n",
    "\n",
    "loss_value.backward() # Calculate the gradients for you\n",
    "optimizer.step() # Update the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-spanking",
   "metadata": {},
   "source": [
    "Check that our loss is reducing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eastern-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss Value: 970.2333984375, Updated Loss Value: 880.2028198242188\n"
     ]
    }
   ],
   "source": [
    "old_loss_value = loss_value\n",
    "prediction = my_model(predictors)\n",
    "loss_value = loss_function(prediction, ground_truth)\n",
    "\n",
    "print(f'Initial Loss Value: {old_loss_value}, Updated Loss Value: {loss_value}')\n",
    "\n",
    "# Reduce learning rate if updated loss is more than initial loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-science",
   "metadata": {},
   "source": [
    "Repeatedly update our model parameters for 500 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "square-majority",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x152974be9160>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwr0lEQVR4nO3deXxb1Z3//9fHkix53+MkthM7JJCdEEKWJjCsZS9b+RZKgU5p05lCh0777UL77Zd2ZuDL9NcCLVPosNNOy1KgQ4ZSSkhYGiCLAyH74sRJbMf7vkm2pPP7Q1eOHcu2HMuxLX2ej4cf1j33Sjo3greOzz33HDHGoJRSKrrEjXUFlFJKRZ6Gu1JKRSENd6WUikIa7kopFYU03JVSKgrZx7oCANnZ2aawsHCsq6GUUhPK1q1b64wxOaH2jYtwLywspLi4eKyroZRSE4qIHBlon3bLKKVUFNJwV0qpKKThrpRSUUjDXSmlopCGu1JKRSENd6WUikIa7kopFYXCDncRsYnIJyLyurVdJCKbRKRERF4UkXir3Gltl1j7C0ep7n10+/y8sPkoXp//VLydUkqNa8Npud8N7Om1/e/AQ8aYmUAjcIdVfgfQaJU/ZB036t7bV8sPXt3B30rqTsXbKaXUuBZWuItIPnAl8KS1LcCFwMvWIc8B11qPr7G2sfZfZB0/qkrr2gO/a9tH+62UUmrcC7fl/jDwPSDY55EFNBljvNZ2OZBnPc4DygCs/c3W8X2IyGoRKRaR4tra2pOrfS+l9YFQP1yv4a6UUkOGu4hcBdQYY7ZG8o2NMY8bY5YYY5bk5ISc92ZYDgdb7nUa7kopFc7EYSuBz4nIFYALSAV+CaSLiN1qnecDFdbxFUABUC4idiANqI94zU8QDHdtuSulVBgtd2PMPcaYfGNMIXATsN4YcwvwDvB567Dbgdesx2usbaz9680or8Lt7vZxrNmN0x5HRWMnXV4dMaOUim0jGef+feDbIlJCoE/9Kav8KSDLKv828IORVXFoR+o7AFhxWhZ+A0cbOkb7LZVSalwb1nzuxph3gXetx4eApSGOcQM3RqBuYQt2xVw4exLv7qvlcF07Mycln8oqKKXUuBIVd6gG+9vPP31SYFv73ZVSMS46wr2+ncykeKZlJZKe6NARM0qpmBcV4V5a105hViIAhVlJ2nJXSsW8qAj3w3UdFGYnAVCUncThOr2gqpSKbRM+3Du7fFS1uCnKCoR7YVYSFU2duLt9Y1wzpZQaOxM+3INdMMGWe2F2oHsmODxSKaVi0YQP9yNWuBf16pYBnYZAKRXbJny4l1r969ODF1StcNeLqkqpWDbhw/1wXTvZyfGkuBwApLocZCfH94x9V0qpWDThw720vp1C62JqUGFWknbLKKVi2oQP98N17T1dMUGF2TrWXSkV2yZ0uLd7vNS0enouogYVZSdR3eKho8s7wDOVUiq6Tehw7xkGGaJbBtCbmZRSMWtih7sV3sGx7UHTMgPb5Y0a7kqp2DShw/3s6Rn88qZFzMjuO71vktMGQKfepaqUilHDms99vJmc5uKaRXn9yp2OQLjrFARKqVgVzgLZLhHZLCKfisguEfmpVf6siJSKyDbrZ5FVLiLyKxEpEZHtIrJ4lM+hH5c9cFoeXW5PKRWjwmm5e4ALjTFtIuIANojIX6x93zXGvHzC8ZcDs6yfZcBj1u9TxqUtd6VUjAtngWxjjGmzNh3Wz2ALXl8D/NZ63kYgXUSmjLyq4XNaLXd3t7bclVKxKawLqiJiE5FtQA2w1hizydp1n9X18pCIOK2yPKCs19PLrbITX3O1iBSLSHFtbe3Jn0EIdlsc9jjRlrtSKmaFFe7GGJ8xZhGQDywVkfnAPcBs4BwgE/j+cN7YGPO4MWaJMWZJTk7O8GodBpfDpn3uSqmYNayhkMaYJuAd4DJjTKXV9eIBngGWWodVAAW9npZvlZ1STnucttyVUjErnNEyOSKSbj1OAC4B9gb70UVEgGuBndZT1gC3WaNmlgPNxpjKUaj7oFwOm/a5K6ViVjijZaYAz4mIjcCXwUvGmNdFZL2I5AACbAP+wTr+DeAKoAToAP4+4rUOg9MRh8erLXelVGwaMtyNMduBs0KUXzjA8Qa4c+RVGxmXXVvuSqnYNaGnHxiMttyVUrEsasPdZbfh0Za7UipGRW+4O+Jwa8tdKRWjojbcnXabDoVUSsWsqA13lyNOb2JSSsWsKA53bbkrpWJX1IZ74A5VbbkrpWJT1Ia7ttyVUrEsasPdaU0cFrinSimlYkv0hruuxqSUimFRG+7B1Zj0RialVCyK4nAPtty1310pFXuiNtyd9uA6qtpyV0rFnqgN92DLXacgUErFougNd7v2uSulYlc4KzG5RGSziHwqIrtE5KdWeZGIbBKREhF5UUTirXKntV1i7S8c5XMIKXhBVVvuSqlYFE7L3QNcaIw5E1gEXGYtn/fvwEPGmJlAI3CHdfwdQKNV/pB13CnnDHbL6I1MSqkYNGS4W4tgt1mbDuvHABcCL1vlzxFYRxXgGmsba/9F1jqrp5R2yyilYllYfe4iYhORbUANsBY4CDQZY7zWIeVAnvU4DygDsPY3A1khXnO1iBSLSHFtbe2ITiIUvaCqlIplYYW7McZnjFkE5ANLgdkjfWNjzOPGmCXGmCU5OTkjfbl+dCikUiqWDWu0jDGmCXgHWAGki0hwge18oMJ6XAEUAFj704D6SFR2OFza566UimHhjJbJEZF063ECcAmwh0DIf9467HbgNevxGmsba/96MwazdzmD0w/o3DJKqRhkH/oQpgDPiYiNwJfBS8aY10VkN/CCiPwb8AnwlHX8U8DvRKQEaABuGoV6Dyk4cZi23JVSsWjIcDfGbAfOClF+iED/+4nlbuDGiNRuBJz2OETAo+GulIpBUXuHqojgtPddR9XvN/z9M5v5oKRuDGumlFKjL2rDHQIjZnp3yzR3dvPOvlrW760Zw1oppdToi+pwdzn6rqPa5gkMyy9v7BirKiml1CkR5eFu6zOfe4u7G4Cyhs6xqpJSSp0S0R3udlvflrs70HIv05a7UirKRXW4Ox1xfaYfaLXCvdXtpbmze6yqpZRSoy6qw91lt/WZOKzVczzQyxq09a6Uil5RHe4nttyD3TIA5Y3a766Uil7RHe4n9Lm39Al3bbkrpaJXONMPTFguR1yfO1TbPF4cNsFpt2nLXSkV1aI83G197lBtdXeT4nIwKcWpfe5KqagW5d0ycX3uUG11e0lx2cnPSNThkEqpqBbV4e5y9J1+oM3tJdlppyAzgfLGTsZgJmKllDolojzc407olgm03AsyEuno8tHQ3jWGtVNKqdET1eHutNvw+g1eXyDgWz1eUlwO8jMSAB0OqZSKXlEd7scXybbC3d1NitNOQWYioNMQKKWiVzjL7BWIyDsisltEdonI3Vb5T0SkQkS2WT9X9HrOPSJSIiL7ROTS0TyBwbiCS+1Z/e5tnuAF1YFb7sYYHn57P69tq+i3TymlJopwhkJ6ge8YYz4WkRRgq4istfY9ZIz5ee+DRWQugaX15gFTgbdF5HRjzClfEsllD4S72+vHGEOr20uyy06Ky0F6oiPkcMhH1pfw8NsHOP+MHK5ZlHeqq6yUUhExZMvdGFNpjPnYetxKYHHswVLvGuAFY4zHGFMKlBBiOb5Twek4vo5qZ7cPn9+Q4nIAUJCR2K/l/urH5Ty4dj8AHV26PJ9SauIaVp+7iBQSWE91k1V0l4hsF5GnRSTDKssDyno9rZwQXwYislpEikWkuLa2dvg1D4PTHuyW8ffMK5PsDPyxkp+R0KfP/cOSOr7/ynY+c1oWq2Zm06nhrpSawMIOdxFJBl4BvmWMaQEeA04DFgGVwC+G88bGmMeNMUuMMUtycnKG89SwHb+g6uuZVybFFQj3gsxAy93vN9S0uPnGHz6mMCuJx750NmkJDjq6vAO+rlJKjXdhTT8gIg4Cwf57Y8yrAMaY6l77nwBetzYrgIJeT8+3yk65YMvd3e0jTgToFe4ZCXR5/dS2efj+K9txd/v4za2BYE+It2nLXSk1oYUzWkaAp4A9xpgHe5VP6XXYdcBO6/Ea4CYRcYpIETAL2By5Kocv2HL3dPtptZbYC/a552cEhkP+7M19vLuvlnsun8NpOckAJMbb6OjWcFdKTVzhtNxXArcCO0Rkm1X2Q+BmEVkEGOAw8HUAY8wuEXkJ2E1gpM2dYzFSBnoNhfT6sLK9p8+9IDMwHPKVj8tZNTObW5dP73leQrxNL6gqpSa0IcPdGLMBkBC73hjkOfcB942gXhHhtAdHy/jpsm5kCnbLBFvuKS47/9+NC4mLO36KiQ47XV4/Xp8fuy2q7/NSSkWpqJ/yFwJ97m0e64Kq09Gz745VRaycmcWUtIQ+z0uMDzyvo9tHqoa7UmoCiolw93j9PeGe7Dp+yj++am7I5yVY4d7Z5SPV6qNXSqmJJKqbpce7ZXy0ur0kxduwxYXqYeqrp+Wu/e5KqQkqqsP9eLdM4Cam3q32wSTGB47Tse5KqYkqqsPdFic4bILH66PV090zDHIoib26ZZRSaiKK6nCHwI1M7m5/YNIwZ7gtd+2WUUpNbFEf7i5HHG6vr2cVpnAkaLgrpSa4qA93p93Wc4dquOEe7HPv7NY+d6XUxBT14R5subd5vD1j3Iei3TJKqYku6sM90HL39SzUEY6ebhmPhrtSamKK+nB3OeJo9/jo6PKF3y3j0Ja7Umpii4Fwt1Hf7gEIe7SM3RZHvC2ODu1zV0pNUFEf7k57HHVtXQDDmkpA53RXSk1kUR/uLoeNxo5AuIfbLQOQpNP+KqUmsJgId2MCj8O9oAracldKTWzhrMRUICLviMhuEdklIndb5ZkislZEDli/M6xyEZFfiUiJtXj24tE+icEEJw8Dwp5+AAJj3cOdW8YYg99vhl03pZQaLeG03L3Ad4wxc4HlwJ0iMhf4AbDOGDMLWGdtA1xOYGm9WcBqAgtpj5ng5GEQ/gVVGN5qTM98cJiV/76ebp9/2PVTSqnRMGS4G2MqjTEfW49bgT1AHnAN8Jx12HPAtdbja4DfmoCNQPoJ662eUk7H8VNMHUa3TGK8jc4w11H9845KKpvd7KhoHnb9lFJqNAyrz11ECoGzgE1ArjGm0tpVBeRaj/OAsl5PK7fKTnyt1SJSLCLFtbW1w6132Jz2Xi33YYZ7OC33Fnc328qaAPjoYP2w66eUUqMh7HAXkWTgFeBbxpiW3vuMMYbAQtlhM8Y8boxZYoxZkpOTM5ynDovLarnb4oSEXl00Q0lw2OnwDN3n/tHBenx+Q7w9jo2HNNyVUuNDWOEuIg4Cwf57Y8yrVnF1sLvF+l1jlVcABb2enm+VjQmX1XJPdtoRGXoVpqDEeBsdYXTLbDhQR2K8jRsW51N8uLFnIW6llBpL4YyWEeApYI8x5sFeu9YAt1uPbwde61V+mzVqZjnQ3Kv75pQLXlAdzhh3CL9bZkNJHcuKMvm707Pp7PaxvbzpZKqplFIRFU7LfSVwK3ChiGyzfq4AHgAuEZEDwMXWNsAbwCGgBHgC+Ebkqx2+4FDI4YyUgcBQyC6vH98gQxzLGjoorWvn3Fk5LCvKArTfXSk1PgyZeMaYDcBA/RkXhTjeAHeOsF4RE2y5D2fqAeg97a93wPHxG0rqADh3VjYZSfHMnpzCxtJ6vsmsEdRYKaVGLgbuULVa7sPslkkIYx3VDQfqyE11MnNSMgArTsui+HAjHq/e2aqUGltRH+7BoZAn0+cOA0/76/MbPjhYx6qZOT0XalfMyMLj9bPtaNPJV1gppSIg6sM92HKPdLjvrGimqaOb807P7ilbVpSFCGw81HCStVVKqciIgXAPDoUcXp97whDrqAb721fOPB7uaYkO5k5J5aNDdSdTVaWUipioD/fgaJmTbbm3D7DU3v7qVvIzEshOdvYpXzEji4+PNuEOc+oCpZQaDVEf7ic7zj1hiKX2qprdTE1L6Fe+bEYWXV5/z5QESik1FqI+3PPSE1h93gwumpM79MG9BFvuA3XLVLW4yU1z9StfWpiJCGzSfnel1BiK+nCPixN+eMUc8tL7t7IHk2Td9BSq5W6MoarZzZQQ4Z6W6GD25FQ2lerNTEqpsRP14X6yBhvn3tTRjcfrJze1f7gDLCvK5OOjOs+MUmrsaLgPIHGQPveqFjdAyJY7wPIZmbi7/TrPjFJqzGi4D8BuiyPeFhc63JsD4T5Qy32pNc/MplLtd1dKjQ0N90EEFsnuf0F1qJZ7ZlI8p+cm6/zuSqkxo+E+iIGm/a1sdiMCOSnOEM8KWFaUxdYjjbquqlJqTGi4DyJhgAU7qpvd5CQ7cdgG/udbNiOTji4fO3VdVaXUGNBwH0RivC3kUnuVLW4mD9AlE7S0KBPQfnel1NjQcB9EosMeslumutnN5AEupgZNSnExIyeJzRruSqkxEM4ye0+LSI2I7OxV9hMRqThhZabgvntEpERE9onIpaNV8VMh0WmjM0S3TGVz55Atdwj0u28pbRh0NSellBoN4bTcnwUuC1H+kDFmkfXzBoCIzAVuAuZZz3lURGyRquypFuqCakeXlxa3N8xwz6TV42VfVetoVVEppUIaMtyNMe8D4fYtXAO8YIzxGGNKCayjunQE9RtTCQ57vztUg2Pch+qWAViYnwbAjoqmPuV+v+G1bRU6kkYpNWpG0ud+l4hst7ptMqyyPKCs1zHlVlk/IrJaRIpFpLi2tnYE1Rg9gZZ73wuqwTHu4YR7YVYSKS4728v7jph570Atd7+wjXf21kSuskop1cvJhvtjwGnAIqAS+MVwX8AY87gxZokxZklOTs5JVmN0heqWqQ6GexjdMnFxwoK8tH7hvsW6yHq0oSNCNVVKqb5OKtyNMdXGGJ8xxg88wfGulwqgoNeh+VbZhJQQb8Pj9fe5IFrZHH64AyzIT2NvVUufRbOLDzcCUKbhrpQaJScV7iIypdfmdUBwJM0a4CYRcYpIETAL2DyyKo6d43O6Hw/m6mY3qS47ifHhLf5xZn463T7Tc1HV4/WxzZpQrLyxM7IVVkopy5AJJSLPA+cD2SJSDtwLnC8iiwADHAa+DmCM2SUiLwG7AS9wpzFmwq43F1xHtaPLS7I1v3tl89A3MPW2IC9wUXV7eTML89PZWdFMl9dPgsNGWaO23JVSo2PIcDfG3Byi+KlBjr8PuG8klRoveqb99fggJVBW3eJmcojl9QaSn5FARqLDmv53OlusLplL5+Xy113VGGMQkQjXXCkV6/QO1UEkOfvP6V7Z7GZy6sAThp1IRFiYn95zUbX4cAMzcpI4syCdzm4f9e1dka20Ukqh4T6oYLdMcB3Vbp+f2jbPsFruEBjvfqCmjY4uL8VHGjlneiYFGYmAXlRVSo0ODfdBBC+oBlvuta0ejAlvjHtvC/LS8PkNa7Ydo6mjmyWFGeRnBr4g9KKqUmo0hDfkI0YlnLDU3lCLdAzkzIJ0AJ7+oBSAcwoze+aC14uqSqnRoOE+iMQTFskeanm9geSmupiU4mR/dRvZyU6mZyUiImQmxVPWoC13pVTkabfMIBJ7hkL2Dffhttzh+Dwz5xRm9IyOKchIoFxb7kqpUaDhPoiEnj73wAXVqhY38fY40hMdw36thfnpACwpzOwpy89I1AuqSqlRoeE+iBO7ZQ7WtDElzXVS49I/c1oW9jjh3FnZPWX5mQlUNHXi1/nelVIRpuE+CIctDodNaO/yUVLTyvp9NVw+f8rQTwxhSWEm2+79LKfnpvSUFWQk0u0zVLe6I1VlpZQCNNyHlBhvp7PLy3+sL8Flt/G1c4tO+rWCUxgEFWQGx7rrRVWlVGRpuA8hMd7GrmMtrPn0GLetmE5Wcvh3pw4lPyMw1l373ZVSkabhPoSEeBvFRxqJt8fx1XNnRPS189KtcNcRM0qpCNNwH0LwouqXlk3vufEoUlwOG7mpTr1LVSkVcRruQ0h02HHa41h9XmRb7UEFOhxSKTUK9A7VIXxlVSEdXT4mDfOu1HAVZCayuTTc9ceVUio8Q7bcrQWwa0RkZ6+yTBFZKyIHrN8ZVrmIyK9EpMRaPHvxaFb+VLhs/hSuX5w/aq+fn5FAZXMn3T7/qL2HUir2hNMt8yxw2QllPwDWGWNmAeusbYDLCSytNwtYTWAhbTWIgoxE/AYqm3Ssu1IqcoYMd2PM+8CJ/QbXAM9Zj58Dru1V/lsTsBFIP2G9VXWC4NS/OmJGKRVJJ3tBNdcYU2k9rgJyrcd5QFmv48qtsn5EZLWIFItIcW1t7UlWY+KbZt3IdKRew10pFTkjHi1jjDEEFsoe7vMeN8YsMcYsycnJGWk1JqwpaQnE2+I4XN8+1lVRSkWRkw336mB3i/W7xiqvAAp6HZdvlakB2OKE6VmJlNZpuCulIudkw30NcLv1+HbgtV7lt1mjZpYDzb26b9QACrOTOKzhrpSKoHCGQj4PfAScISLlInIH8ABwiYgcAC62tgHeAA4BJcATwDdGpdZRZkZ2EkfqO/Dp1L9KqQgZ8iYmY8zNA+y6KMSxBrhzpJWKNYXZSXT5/Bxr6uyZKVIppUZCpx8YBwqzkgD0oqpSKmI03MeBGTmBcNeLqkqpSNFwHwcmpThJjLdpuCulIkbDfRwQEaZn6YgZpVTkaLiPEzOyk7TlrpSKGA33caIwO5GyRp0dUikVGRru40RRdjI+v9FVmZRSEaHhPk4UZQfGt5fWtY1xTZRS0UDDfZwIjnUvrdPZIZVSI6fhPk5kJsWT6rJry10pFREa7uOEiFCUncRhbbkrpSJAw30cKdThkEqpCNFwH0eKspM41tyJu9s31lVRSk1wGu7jSFF2EsbA0QbtmlFKjYyG+zhSlB0YMXOwRi+qKqVGRsN9HJmRk0yqy853/vgpD67dT5vHO+LX9PkNv3hrH998/pN++7YcbuDqRzbQ6u4e8fsopcaXEYW7iBwWkR0isk1Eiq2yTBFZKyIHrN8Zkalq9Et22nntrlVcMHsSv1p3gL/72TtsOFDX77jDde3UtXn6lX9a1sSLW47S3BkI6zaPl6//rphH1pfwP58eo7a173PW7q5mR0UzHx2sH50TUkqNmUi03C8wxiwyxiyxtn8ArDPGzALWWdsqTEXZSfz6i4t57c6VZCbF808vfEJNq7tn/8HaNq56ZAP3vrar33P/9fXdfP+VHSy7/22+/dI2Pv/Yh7yzr5YbFucDsOtYc5/jg9sbSvp/gSilJrbR6Ja5BnjOevwccO0ovEfUO7MgnUdvWUy7x8v3X96OMYZ2j5d/+N1W2jxetpU19Tne5zfsrmzhkrm53LA4n7d2VVPR1MkzXz6H/3v1XAB2HWvpOd4Yw25rW8Ndqegz5BqqQzDAWyJigP80xjwO5BpjKq39VUBuqCeKyGpgNcC0adNGWI3oNCs3hR9eMYd71+zivzYdZUtpAyW1bVw4exLr99bQ2N5FRlI8EFjFqaPLx2fn5nLjkgJ+fFUg0F0OGwAFmQnsrjwe7pXNbho7uinKTuJQbTvHmjqZmp5w6k9SKTUqRtpyX2WMWQxcDtwpIuf13mktmG1CPdEY87gxZokxZklOTs4IqxG9blsxnfNOz+He13ay5tNjfOeS0/nqqiIAdvbqZgl2scybmgYEQj0Y7ADzpqT1tNQDxwcef/XcwGt9oK13paLKiMLdGFNh/a4B/gQsBapFZAqA9btmpJWMZSLCzz+/kMwkJxfPyeUb58/sCfCdFX3DOt4Wx6zc5JCvM3dqKqV17T0jcHYda0YErl2UR3ZyvIa7UlHmpMNdRJJEJCX4GPgssBNYA9xuHXY78NpIKxnrJqW6eO+75/P4rWcTFyekJTooyExgZ0XflvsZk1Nw2EJ/pPOmpgKwx+qa2X2shaLsJJKcdlbOzGZDST2BP7SUUtFgJC33XGCDiHwKbAb+bIx5E3gAuEREDgAXW9tqhJKcduLipGd7QV5aT7eMMYadFS3Mz0sd8PnB1v4u6wth17GWnrKVM7Opa/Owr7p1tKqvlDrFTvqCqjHmEHBmiPJ64KKRVEoNbd7UNN7YUUVzZzet7m6aO7t7wjqU3FQnWUnx7DrWQlNHFxVNndy6YjoAq2ZmA7DhQB2zJw/8BaGUmjj0DtUJan6e1RI/1tzT9x7seglFRJg7NZXdlS09F1bnTgkcPzU9gRk5SdrvrlQU0XCfoOZbQb6rooXdx5qxxQlzpgze6p47NZX91a1sK28C+n4ZrJqZzabSBrq8ukC3UtFAw32Cykp2MjXNxc5jzew81sLMnOQ+Qx9DmTc1jW6fYc22Y0xOdZGV7OzZd96sHDq6fHxwMLKt97/uquLDCL+mUmpoGu4T2Ly8NHZUNLPrWPOgXTI9x1vH7K1qZe4Jx597ejbpiQ7+9HHFoK+x4UAdb+6s5N19NWw90ojfP/AIm26fn+/+8VN+sqb/VAm91bd5+t1xq5QamZHeoarG0PypaazdXQ0Egn4ohVlJJMbb6Ojy9fsycNptfO7Mqby4pYwWdzepLke/57+7r4YvP7OlT9kXl03j/usWhHy/jYfqaXF7aXG3UdbQQUFmYsjjvv/KDt7eU81Prp7Ll1cWDXkeSqmhact9AluQfzyg54fRcrfFCbMnpwChL75evzgfj9fPX3ZU9tvX7fPzL6/vpjArkde/uYpX/vEz3Lx0Gn/YdJRNh0LPKvnXXVXYreGb7+wLfS9bVbOb9XuryUyK5yf/s5tH1h3Q8fZKRYCG+wQ2v9fQxxO7WQYSHC45d0r/lv6Z+WnMyEnila39u2Z++9ERDtW28+Or5jI/L42zp2fw46vmkJ+RwD2v7ui3NKDfb/jrrmoumZvL9KxE1u8NHe5/LC7Db+CP/7CC68/K4xdr9/PAm3vDOhel1MA03CewSakuclKcFGYlkhKiGyWUL5xTwNfOLaIgs/8kYSLCDYvz2Xy4gaP1x5f6q2/z8PDb+znv9BwunD2ppzwx3s791y3gUF07v36npM9rfVLWSG2rh8vmT+aCMybx0cF6Orv6fwG8sKWMlTOzOC0nmZ/feCZfWFLAf753iIO1A69G1e7x8ruPDtMyjEVGPiipo7rFPfSBSkUJDfcJ7vYV07ll2fSwj5+fl8aPrpyLiITcf91ZeYjAq5+U95T9/K39dHb5+L9Xzen3vPNOz+G6s/J47N2D7Ks6fofrX3dV47AJF8yexEVzJuHx+vuNmvlbSR0VTZ3cdE5gVtC4OOF/X3oG9jjhpS1lA57DL9cd4Mev7eL6Rz/kSH17T7kxhpKaNnwnXOR9bVsFtzy5iasf2dBvTnulopWG+wR314Wz+Np5MyL2elPTE/jMaVm88nE5z3xQyk2Pf8Tzm49y24pCZk5KCfmcH181l7QEB6t/V0xdmwdjDG/urGLlzGxSXQ6WFmWSGG/r1zXzwuajZCQ6+Oy847NC56QEJkh7eWt5yDH3ZQ0dPPvBYVbMyKKuzcM1v/6A9Xuree7Dw1z68Ptc/OB7fPW5LT1LB+4ob+Z7L2/nzIJ0bHHC//rNR7y/vzZi/15KjVca7qqf68/Kp6yhk5/+z24a2rv4p4tm8d1Lzxjw+MykeJ64fQnVLW7ueHYLHx9t5GhDB5fNmwwERuKsmpnNO3trei6W1rZ6WLu7mhsW5+O09x2f/4WlBdS3d7FuT3W/93rgzb3Y4oSHvrCI//7GSrKS4vnKs8Xcu2YXLoeNr64q4v0Dddzw2Id8fLSR1b8rJjvZyVO3L+FP31hJQWYiX3l2C4++W9Kvm0ipaKJDIVU/1yyait0mLMxPpyg7KaznLJ6WwSM3L+brvyvmy89sIU7g4rnHW+QXzp7EW7ur2VfdGlhK8J0SvH7DTUsL+r3WebNymJLm4oUtZVy+YEpP+dYjjfx5eyX/dNEsJqe5APjTnSv5/cajrJyZxcL8dAAumD2Jf/yvrVz/6Ie4HHG88o+fIdu6YeuP/7CCb7/0KT97cx/PfHCYuy6YyRfOKRjyBrBQWtzdHKhu4+zpfZcJNsZQWtdOUXbSgN1fHq+Pkpo2zshNwT7ATJ4nY/exFnYea+Z/Len/73oq/ea9g7i7fXzzwlnY4kL/G6jRJeNh2NmSJUtMcXHxWFdDRcDvNx3hR3/aydKiTF76+oqe8uoWN8vuX8e5s7LZX91KdYuHqxZO4T++uDjk6zy4dj+PrD/A3753AfkZiRhjuOGxDzna0Ml73z2fJOfg7ZJDtW3cu2YXX1o+nUutvyB621zawM/f2sfm0gac9jjOmpbO8hlZXH3mVE7LCT0nfm/1bR5ueXITe6ta+cWNZ3LD2fk9+/719d08taGUKxdO4f5rF5CWGLjYXdPi5sUtZXx4sJ6Pjzbi8fr52rlF/OjKuSHfY2dFMz94dTvzp6Zx/3UL+swKGoq728fFD75HeWMnT395CRfODrkI2qj70yfl/POLnwJw2bzJPHzTopP68lRDE5Gtvdav7rtPw11F2l92VFKUk9RvhsmrH9nAjopmlhVl8s0LZ7FyZtaALdvyxg7O/dk7geNOy+KJv5Xy9p5q/t/1C7h5aWSWZTTGsPFQA+v2VLOxtJ5dx1pIirfz7N+fw5LCzAGfV9vq4ZYnN3K0oYOZk5LZV9XK77+6nKVFmTy9oZR/eX03y4oy2XqkkZwUJ/dcMYcPS+p49eMKuv1+5k5JZVlRFseaOnlrdxWvfmMliwrSe17f5zc8/v4hHly7D5fDRqvby81Lp3H/dfMH/PcCeGjtfn657gC5qU4EYe23z+s3iupofQd/3VXFtvImpqS6mJ6VyKzcFJYVZQ762gPp6PISb4vr+etjT2UL1z36AQvz07lkTi73/2UPi6dl8MRtS8i0loQMh99vwvoyq25xU9vqocXdzbKirCG/9INe21ZBstPORXPG5gswUjTc1bhwpL6dxo7uPkE2mNue3syGA7X4DaQnOrht+XTuvvj0Ufszv6Kpk1uf3ERVi5unbj+HFadl0eX18+6+Gg7UtJEUbyMx3s5/vn+QY01unvryEuZNSeO6Rz+gsaOLOy+YyX1v7OGzc3N59Jaz2XWsmW+9sI1Dde047XHcuCSfr507g+lZga6uVnc3n33ofVJcdl7/5rnE2+OoanZz9wufsKm0gSsWTOa+axfw5IZD/Pqdg3xlZRE/DjFiCQL/tpc89D6XzZvMV1YVcf2jH3Dz0mncd90CjDGs+fQYj717kL3WiKa89ATq2jx4rIvWt62Yzk+unjdkoPa2r6qVLz6xEbtN+OLS6Vy5cAp3PLcFd7eP1795LjkpTt7YUcm3XtyGyx7HJXMnc8WCyaycmR2yJd/l9fPW7ir+a+MRdla08PMbz+Sy+f3/6oLADXJ3v/AJ7u7jF91n5CTxmy+dzem5KT2f51N/K2V6ViJfXDYNhy0Ov99w/xt7eHJDKSLwb9fO7xlt1tzRzQ//ewcHa9q484KZXLlgyrD+PcbCmIS7iFwG/BKwAU8aYwZctEPDXYWyubSBX7y1j2sW5XHdWXkkxI/+n/Y1rW5ueWITRxs6uGrhVNbtraapo+94+qR4G09/+RyWzcgC4HBdO9c++gFNHd2cNS2dP3x1eU9dO7q8vLevlnOKMnv6/Xtbv7earzxbzN0XzeKsael8+6VPcXf7+Onn5vH5s/MREYwx/Mvru3nmg8OcOyubuVNTKcpKYt7UNOZNTSUuTrjj2S1sPFTP+v99PrmpLv7t9d08uaGUB65fwGvbjvHRoXrmTEnlhsV5fHbuZKZlJeL3G2paPTz5t0M8uaGUG8/O54EbFvb78tx9rIU/bi1jUUE6Vy+cSlycsK+qlZuf2IjDJpwxObVnBJLDJrywejlnTz/+l8+O8mae/fAwa3dX0eL29iwHOXdKKpPTXNS1eahp8bC9opnaVg/5GQkkO+3sq27lR1fM4Y5VRX2+0F7bVsG3X/qUBXlpfGn5dCalOOno8vF//nsn7R4vP/3cPI42dPDE3w7h9Rt8fsPpucncc8UcXtxcxpu7qrh9xXTKGztZt7eGH14xm6VFWdz1h4+panaTn5HA4foOzshN4a4LZ3LpvMnE24d3XcTnNxyoaeW0nOQBV0eLhFMe7iJiA/YDlwDlwBbgZmPM7lDHa7ir8aS+zcOtT23mYG0bn503mevPymPZjEw83X7au7ykuBykJfTt7th6pIHnPjzCvVfP7TPbZjjufuETXt9eic9vmD05hf/44mJmTurb72+M4Rdv7efNXVUcqW+n2xf4/zYj0cGC/HTe31/Lj66Y0zMstrPLx6UPv8/Rhg7SEhx899IzuHnptJB/9RhjePjtA/xy3QGuXDiFzy/OJyHehsfr57kPD7N+bw1xAn4Dc6akcvuK6fzsr/tw2ITnv7acGTnJlNa188KWoyzIS+OqhVNDnmeXda/DR4fq2X0ssK5AQ0cXWUnxTEpxUZidyI1nF3De6Tl0ef18+6Vt/GVnFTedU8DFc3LJTnGyvbyJe9fsYllRJk/efg7Jvbphalrc3PWHT9h8uAGAaxdN5XuXzWZnRTP/+ufdlDV0IgL/58q53LGqiG6fn39+cRuvb6/EFidMTnXxH188i4X56fx5RyUPv72fQ7XtZCXFc8PZ+Vw+fzIpLjvxNhvtXV62HG5gU2kDpbXtnD09g/PPyOH03BTWfHqM5zcfpbyxkylpLr78mUJuXjatz3xNnV0+dlQ0s62skflT0/iMtWDOcI1FuK8AfmKMudTavgfAGPP/Qh2v4a7Gmy6vH5/fnJK/FurbPHzh8Y0sK8rkx1fNHfLio9fnp6Kpk0+ONvH+gVr+dqCOyakuXv3GZ/q0EndWNPPnHZV8dVVRWF84v3nvIA/8pe/UD+mJDr6ysohbl0/nvf21PLh2P0cbOshNdfYE+8kyJtCqHmi0kN9veODNvTz+/qE+5eefkcNvvnR2yH8nr8/P81vKmD81lbOmHR/F5O728V8bj3BaTjIX9LrL2uc33PfnPTR1dHHv1fN6Ln4H971/oJYXNh9l3Z4avCFmQJ2S5qIoO4lPjjbR2WsKjhUzsrhs/mTe3FnFR4fqSXDYyE6Jx2b9BVLW2Nlzs93X/24G91w+J5x/sn7GItw/D1xmjPmqtX0rsMwYc1evY1YDqwGmTZt29pEjRyJeD6ViQfD/4ZO5IHqisoYO6to8dHb56PL5Oacws89Fyi6vn7/srGTxtIwBZ/mMtJoWN5XNburaPHR5/Vw0J3fY3SQjrkOrm4+PNOHx+uj2GRw2YfG0DPIzEhARPF4fxYcb2X2shQtm5/S54W9nRTMvby2nubMbn9/gM4YZ2UksKkjnzIL0kN114RqX4d6bttyVUmr4Bgv30fr6qwB630WRb5UppZQ6BUYr3LcAs0SkSETigZuANaP0XkoppU4wKtMPGGO8InIX8FcCQyGfNsYMvtaaUkqpiBm1uWWMMW8Ab4zW6yullBqYzgqplFJRSMNdKaWikIa7UkpFIQ13pZSKQuNiVkgRqQVO9hbVbKBuyKOiTyyedyyeM8TmecfiOcPwz3u6MSYn1I5xEe4jISLFA92hFc1i8bxj8ZwhNs87Fs8ZInve2i2jlFJRSMNdKaWiUDSE++NjXYExEovnHYvnDLF53rF4zhDB857wfe5KKaX6i4aWu1JKqRNouCulVBSa0OEuIpeJyD4RKRGRH4x1fUaDiBSIyDsisltEdonI3VZ5poisFZED1u+MoV5rIhIRm4h8IiKvW9tFIrLJ+sxftKaUjhoiki4iL4vIXhHZIyIrYuGzFpF/tv773ikiz4uIKxo/axF5WkRqRGRnr7KQn68E/Mo6/+0isng47zVhw91ahPvXwOXAXOBmEZk7trUaFV7gO8aYucBy4E7rPH8ArDPGzALWWdvR6G5gT6/tfwceMsbMBBqBO8akVqPnl8CbxpjZwJkEzj2qP2sRyQP+CVhijJlPYJrwm4jOz/pZ4LITygb6fC8HZlk/q4HHhvNGEzbcgaVAiTHmkDGmC3gBuGaM6xRxxphKY8zH1uNWAv+z5xE41+esw54Drh2TCo4iEckHrgSetLYFuBB42Tokqs5bRNKA84CnAIwxXcaYJmLgsyYw/XiCiNiBRKCSKPysjTHvAw0nFA/0+V4D/NYEbATSRWRKuO81kcM9DyjrtV1ulUUtESkEzgI2AbnGmEprVxWQO1b1GkUPA98D/NZ2FtBkjPFa29H2mRcBtcAzVlfUkyKSRJR/1saYCuDnwFECod4MbCW6P+veBvp8R5RxEzncY4qIJAOvAN8yxrT03mcC41mjakyriFwF1Bhjto51XU4hO7AYeMwYcxbQzgldMFH6WWcQaKUWAVOBJPp3XcSESH6+EzncY2YRbhFxEAj23xtjXrWKq4N/olm/a8aqfqNkJfA5ETlMoMvtQgL90enWn+4QfZ95OVBujNlkbb9MIOyj/bO+GCg1xtQaY7qBVwl8/tH8Wfc20Oc7ooybyOEeE4twW/3MTwF7jDEP9tq1Brjdenw78NqprttoMsbcY4zJN8YUEvhs1xtjbgHeAT5vHRZV522MqQLKROQMq+giYDdR/lkT6I5ZLiKJ1n/vwfOO2s/6BAN9vmuA26xRM8uB5l7dN0MzxkzYH+AKYD9wEPjRWNdnlM5xFYE/07YD26yfKwj0P68DDgBvA5ljXddR/Dc4H3jdejwD2AyUAH8EnGNdvwif6yKg2Pq8/xvIiIXPGvgpsBfYCfwOcEbjZw08T+C6QjeBv9TuGOjzBYTAiMCDwA4Co4nCfi+dfkAppaLQRO6WUUopNQANd6WUikIa7kopFYU03JVSKgppuCulVBTScFdKqSik4a6UUlHo/wd+gpYtKgIPaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "loss_values = []\n",
    "X_train = torch.tensor(dataset[['X_1', 'X_2']].to_numpy(), dtype=torch.float32)\n",
    "y_train = torch.tensor(dataset[['Crate_Count']].to_numpy(), dtype=torch.float32)\n",
    "for idx in range(100):\n",
    "    shuffled_indices = torch.randperm(X_train.shape[0])\n",
    "    \n",
    "    for idx in range(0, X_train.shape[0], batch_size):\n",
    "        batch_indices = shuffled_indices[idx : idx + batch_size]\n",
    "        predictors = X_train[batch_indices]\n",
    "        ground_truth = y_train[batch_indices]\n",
    "        \n",
    "        optimizer.zero_grad() # Zero out gradients for all the parameters in our model\n",
    "\n",
    "        prediction = my_model(predictors)\n",
    "        loss_value = loss_function(prediction, ground_truth)\n",
    "\n",
    "        loss_value.backward() # Calculate the gradients\n",
    "        optimizer.step() # Update the model parameters\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        updated_loss_value = loss_function(my_model(predictors), ground_truth) # Calculate updated loss value\n",
    "        loss_values.append(updated_loss_value)\n",
    "        \n",
    "plt.plot(np.arange(100), loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-winner",
   "metadata": {},
   "source": [
    "Check the $R^2$ of the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fatty-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938615011546952"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.r2_score(dataset['Crate_Count'], my_model(X_train).detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-petersburg",
   "metadata": {},
   "source": [
    "**Try it out**  \n",
    "1. Try to change the number of neurons and see visualize the difference in our model approximation\n",
    "2. Try to approximate a different target function\n",
    "3. Ask questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-brake",
   "metadata": {},
   "source": [
    "## Completion\n",
    "Congratulations on completing this lab session.  \n",
    "With the knowledge and intuition gained from this lab session we are ready to move on to our challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
